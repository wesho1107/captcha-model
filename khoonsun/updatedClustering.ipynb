{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from typing import List, Tuple, Optional\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_characters_from_filename(filename: str) -> Tuple[List[str], int]:\n",
    "    characters = filename.split('/')[-1].split('-0.png')[0]\n",
    "    return characters, len(characters)\n",
    "\n",
    "def get_rgb_image(image: np.ndarray) -> np.ndarray:\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def get_gray_image(image: np.ndarray) -> np.ndarray:\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def load_image(image_path: str) -> np.ndarray:\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "def show_image(image: np.ndarray) -> None:\n",
    "    # Detect if image is grayscale or color\n",
    "    plt.figure(figsize=(3,2))\n",
    "    if len(image.shape) == 2:\n",
    "        # Grayscale image\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        # Color image - convert from BGR to RGB for matplotlib\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_image(image: np.ndarray) -> np.ndarray:\n",
    "    # Clean image from black lines and noise\n",
    "    gray = get_gray_image(image)\n",
    "    # Added this part: use HSV saturation to avoid killing dark colored strokes.\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    S = hsv[..., 1]\n",
    "    black_mask = ((gray < 1) & (S < 60))\n",
    "    # black_mask = gray < 1  # Adjust threshold\n",
    "    black_mask = black_mask.astype(np.uint8) * 255\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    cleaned_mask = cv2.morphologyEx(black_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    # Added this part: small close + dilate to join broken line pixels so we can remove them cleanly.\n",
    "    cleaned_mask = cv2.dilate(cleaned_mask, kernel, iterations=1)\n",
    "    inverse_mask = cv2.bitwise_not(cleaned_mask)\n",
    "    img_rgb_clean = image.copy()\n",
    "    img_rgb_clean[inverse_mask == 0] = [255, 255, 255]\n",
    "    return img_rgb_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Dilate the image to strengthen character pixels.\n",
    "    \"\"\"\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    invert_image = cv2.bitwise_not(image)\n",
    "    invert_image = cv2.dilate(invert_image, kernel, iterations=2)\n",
    "    return cv2.bitwise_not(invert_image)\n",
    "\n",
    "def get_k_means_clusters(image: np.ndarray, num_characters: int) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Apply k-means clustering to segment characters by color.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (h, w, 3)\n",
    "        num_characters: Number of characters to segment\n",
    "    \n",
    "    Returns:\n",
    "        List of binary masks, one per character cluster\n",
    "    \"\"\"\n",
    "    # Remove white background pixels\n",
    "    mask_nonwhite = np.any(image < 240, axis=-1)\n",
    "    pixels = image[mask_nonwhite]\n",
    "    # Added this part: guard k so it never exceeds the number of pixels we actually cluster.\n",
    "    k = min(num_characters, pixels.shape[0]) \n",
    "    pixels = np.float32(pixels)\n",
    "\n",
    "    # Apply k-means clustering\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    # _, labels, centers = cv2.kmeans(pixels, num_characters, None, criteria, 1, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    # Added this part: improves convergence and color separation for small/noisy images.\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 5, cv2.KMEANS_PP_CENTERS) \n",
    "\n",
    "    # Create masks per cluster and remove noise\n",
    "    h, w, _ = image.shape\n",
    "    cluster_masks = []\n",
    "    label_image = np.full((h, w), -1, dtype=np.int32)\n",
    "    label_image[mask_nonwhite] = labels.flatten()\n",
    "\n",
    "    # Removing noise\n",
    "    # min_area = 40   # Minimum area for a \"blob\" to be kept as a character, adjust as needed\n",
    "    \n",
    "    # Added this part: keeps tiny specks out without killing real strokes across different sizes.\n",
    "    # Removing noise (scale-aware)\n",
    "    h, w, _ = image.shape\n",
    "    # area threshold proportional to image area (0.15% of image), but never below 40\n",
    "    min_area = max(40, int(0.0015 * h * w))\n",
    "\n",
    "    for i in range(k):\n",
    "        cluster_mask = (label_image == i).astype(np.uint8) * 255\n",
    "\n",
    "        # Remove small connected components (\"noise dots\"): keep only blobs >= min_area\n",
    "        num_labels, comp_labels, stats, centroids = cv2.connectedComponentsWithStats(cluster_mask, connectivity=8)\n",
    "        clean_mask = np.zeros_like(cluster_mask)\n",
    "        for j in range(1, num_labels):  # skip background\n",
    "            area = stats[j, cv2.CC_STAT_AREA]\n",
    "            if area >= min_area:\n",
    "                clean_mask[comp_labels == j] = 255\n",
    "\n",
    "        # Optional: Morphological closing can help connect fragmented parts of actual characters a bit, but not too aggressive\n",
    "        ks = max(3, int(round(min(h, w) * 0.01)))   # ~1% of min dimension\n",
    "        if ks % 2 == 0: ks += 1\n",
    "        kernel_close = np.ones((ks, ks), np.uint8)\n",
    "        clean_mask = cv2.erode(clean_mask, kernel_close, iterations=1)\n",
    "        # clean_mask = cv2.morphologyEx(clean_mask, cv2.MORPH_CLOSE, kernel_close, iterations=1)\n",
    "        # Added this part: gentle morphology to connect slightly fragmented strokes, then open dots.\n",
    "        clean_mask = cv2.morphologyEx(clean_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8), iterations=1)\n",
    "\n",
    "        cluster_masks.append(clean_mask)\n",
    "    \n",
    "    return cluster_masks\n",
    "\n",
    "def get_k_means_clusters_lab(image: np.ndarray, num_characters: int) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Apply k-means clustering to segment characters by color in LAB color space.\n",
    "    LAB color space is perceptually uniform, which can provide better color-based segmentation.\n",
    "    \n",
    "    Args:\n",
    "        image: RGB image (h, w, 3)\n",
    "        num_characters: Number of characters to segment\n",
    "    \n",
    "    Returns:\n",
    "        List of binary masks, one per character cluster\n",
    "    \"\"\"\n",
    "    # Convert RGB to LAB color space for perceptually uniform clustering\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "    # Remove white background pixels (check in RGB space)\n",
    "    mask_nonwhite = np.any(image < 240, axis=-1)\n",
    "    pixels_lab = image_lab[mask_nonwhite]\n",
    "    pixels_lab = np.float32(pixels_lab)\n",
    "\n",
    "    # Apply k-means clustering in LAB space\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(pixels_lab, num_characters, None, criteria, 10, cv2.KMEANS_PP_CENTERS)\n",
    "\n",
    "    # Create masks per cluster and remove noise\n",
    "    h, w, _ = image.shape\n",
    "    cluster_masks = []\n",
    "    label_image = np.full((h, w), -1, dtype=np.int32)\n",
    "    label_image[mask_nonwhite] = labels.flatten()\n",
    "\n",
    "    # Removing noise\n",
    "    min_area = 40   # Minimum area for a \"blob\" to be kept as a character, adjust as needed\n",
    "    kernel_close = np.ones((3, 3), np.uint8)  # for closing isolated dots\n",
    "\n",
    "    for i in range(num_characters):\n",
    "        cluster_mask = (label_image == i).astype(np.uint8) * 255\n",
    "\n",
    "        # Remove small connected components (\"noise dots\"): keep only blobs >= min_area\n",
    "        num_labels, comp_labels, stats, centroids = cv2.connectedComponentsWithStats(cluster_mask, connectivity=8)\n",
    "        clean_mask = np.zeros_like(cluster_mask)\n",
    "        for j in range(1, num_labels):  # skip background\n",
    "            area = stats[j, cv2.CC_STAT_AREA]\n",
    "            if area >= min_area:\n",
    "                clean_mask[comp_labels == j] = 255\n",
    "\n",
    "        # Optional: Morphological closing can help connect fragmented parts of actual characters a bit, but not too aggressive\n",
    "        clean_mask = cv2.erode(clean_mask, kernel_close, iterations=1)\n",
    "        clean_mask = cv2.morphologyEx(clean_mask, cv2.MORPH_CLOSE, kernel_close, iterations=1)\n",
    "\n",
    "        cluster_masks.append(clean_mask)\n",
    "    \n",
    "    return cluster_masks\n",
    "    \n",
    "\n",
    "def reconstruct_from_clusters(cluster_masks: List[np.ndarray]) -> np.ndarray:\n",
    "    h, w = cluster_masks[0].shape\n",
    "    reconstructed = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    for mask in cluster_masks:\n",
    "        reconstructed = cv2.bitwise_or(mask, reconstructed)\n",
    "    \n",
    "    return reconstructed\n",
    "\n",
    "def get_contours_from_masks(cluster_masks: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    contours = []\n",
    "    for mask in cluster_masks:\n",
    "        mask_contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours.extend(mask_contours)\n",
    "    \n",
    "    return contours\n",
    "\n",
    "def get_bounding_boxes(contours: List[np.ndarray]) -> List[Tuple[int, int, int, int]]:\n",
    "    return [cv2.boundingRect(contour) for contour in contours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _uf_find(x, parent):\n",
    "    if parent[x] != x:\n",
    "        parent[x] = _uf_find(parent[x], parent)\n",
    "    return parent[x]\n",
    "\n",
    "def _uf_union(x, y, parent):\n",
    "    px, py = _uf_find(x, parent), _uf_find(y, parent)\n",
    "    if px != py:\n",
    "        parent[px] = py\n",
    "\n",
    "def _merge_groups(bounding_boxes, groups):\n",
    "    merged_boxes = []\n",
    "    for group in groups.values():\n",
    "        # Find bounding box that contains all boxes in the group\n",
    "        min_x = min(x for x, y, w, h in group)\n",
    "        min_y = min(y for x, y, w, h in group)\n",
    "        max_x = max(x + w for x, y, w, h in group)\n",
    "        max_y = max(y + h for x, y, w, h in group)\n",
    "        merged_boxes.append([min_x, min_y, max_x - min_x, max_y - min_y])\n",
    "    # Sort by x-coordinate\n",
    "    merged_boxes.sort(key=lambda box: box[0])\n",
    "    return merged_boxes\n",
    "\n",
    "def merge_boxes_small_nearby(bounding_boxes, width_threshold=0.5, height_threshold=0.5, distance_threshold=30):\n",
    "    \"\"\"\n",
    "    Merge small bounding boxes with nearby larger boxes.\n",
    "    This is useful for merging character fragments (dots, diacritics, noise) with main characters.\n",
    "    A box is considered \"small\" if its width OR height is below the threshold.\n",
    "    Returns:\n",
    "        List of merged bounding boxes\n",
    "    \"\"\"\n",
    "    if not bounding_boxes or len(bounding_boxes) <= 1:\n",
    "        return bounding_boxes\n",
    "\n",
    "    widths = [w for x, y, w, h in bounding_boxes]\n",
    "    heights = [h for x, y, w, h in bounding_boxes]\n",
    "    median_width = np.median(widths)\n",
    "    median_height = np.median(heights)\n",
    "\n",
    "    small_width_threshold = median_width * width_threshold\n",
    "    small_height_threshold = median_height * height_threshold\n",
    "\n",
    "    # Create list with indices and dimensions\n",
    "    boxes_with_info = []\n",
    "    for idx, box in enumerate(bounding_boxes):\n",
    "        x, y, w, h = box\n",
    "        center_x = x + w / 2\n",
    "        center_y = y + h / 2\n",
    "        is_small = (w < small_width_threshold) or (h < small_height_threshold)\n",
    "        boxes_with_info.append({\n",
    "            'idx': idx,\n",
    "            'box': box,\n",
    "            'width': w,\n",
    "            'height': h,\n",
    "            'center': (center_x, center_y),\n",
    "            'is_small': is_small,\n",
    "            'merged_with': None\n",
    "        })\n",
    "\n",
    "    n = len(bounding_boxes)\n",
    "    parent = list(range(n))\n",
    "\n",
    "    def distance(center1, center2):\n",
    "        return np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n",
    "\n",
    "    # For each small box, find the nearest larger box\n",
    "    for i, box_i in enumerate(boxes_with_info):\n",
    "        if not box_i['is_small']:\n",
    "            continue\n",
    "\n",
    "        nearest_idx = None\n",
    "        nearest_dist = float('inf')\n",
    "        for j, box_j in enumerate(boxes_with_info):\n",
    "            if i == j or box_j['is_small']:\n",
    "                continue\n",
    "            dist = distance(box_i['center'], box_j['center'])\n",
    "            if dist < nearest_dist:\n",
    "                nearest_dist = dist\n",
    "                nearest_idx = j\n",
    "        if nearest_idx is not None and nearest_dist <= distance_threshold:\n",
    "            _uf_union(i, nearest_idx, parent)\n",
    "    # Group boxes by their root parent\n",
    "    groups = {}\n",
    "    for i in range(n):\n",
    "        root = _uf_find(i, parent)\n",
    "        if root not in groups:\n",
    "            groups[root] = []\n",
    "        groups[root].append(bounding_boxes[i])\n",
    "\n",
    "    return _merge_groups(bounding_boxes, groups)\n",
    "\n",
    "def merge_boxes_overlapping_x(bounding_boxes, overlap_threshold=1.0):\n",
    "    \"\"\"\n",
    "    Merge bounding boxes if their x-ranges overlap by more than overlap_threshold.\n",
    "    Returns:\n",
    "        List of merged bounding boxes\n",
    "    \"\"\"\n",
    "    if not bounding_boxes:\n",
    "        return []\n",
    "\n",
    "    n = len(bounding_boxes)\n",
    "    parent = list(range(n))\n",
    "\n",
    "    # Check all pairs for overlap\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            x1, y1, w1, h1 = bounding_boxes[i]\n",
    "            x2, y2, w2, h2 = bounding_boxes[j]\n",
    "            x1_start, x1_end = x1, x1 + w1\n",
    "            x2_start, x2_end = x2, x2 + w2\n",
    "\n",
    "            overlap_start = max(x1_start, x2_start)\n",
    "            overlap_end = min(x1_end, x2_end)\n",
    "            overlap_width = max(0, overlap_end - overlap_start)\n",
    "\n",
    "            min_width = min(w1, w2)\n",
    "            overlap_pct = overlap_width / min_width if min_width > 0 else 0\n",
    "\n",
    "            if overlap_pct > overlap_threshold:\n",
    "                _uf_union(i, j, parent)\n",
    "\n",
    "    # Group boxes by their root parent\n",
    "    groups = {}\n",
    "    for i in range(n):\n",
    "        root = _uf_find(i, parent)\n",
    "        if root not in groups:\n",
    "            groups[root] = []\n",
    "        groups[root].append(bounding_boxes[i])\n",
    "\n",
    "    return _merge_groups(bounding_boxes, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_hist_in_bounding_box(bounding_box, image: np.ndarray):\n",
    "    x, y, w, h = bounding_box\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_RGB2HSV)\n",
    "    hue = hsv_roi[..., 0].flatten()\n",
    "    sat = hsv_roi[..., 1].flatten()\n",
    "    val = hsv_roi[..., 2].flatten()\n",
    "    not_white_mask = ~((sat < 20) & (val > 200))\n",
    "    hue_filtered = hue[not_white_mask]\n",
    "    sat_filtered = sat[not_white_mask]\n",
    "\n",
    "    if len(hue_filtered) == 0 or len(sat_filtered) == 0:\n",
    "        return [], [], [], []\n",
    "    \n",
    "    # Dominant hue\n",
    "    hue_hist, hue_bin_edges = np.histogram(hue_filtered, bins=36, range=(0, 180))\n",
    "    # Dominant saturation\n",
    "    sat_hist, sat_bin_edges = np.histogram(sat_filtered, bins=16, range=(0, 256))\n",
    "\n",
    "    return hue_hist, sat_hist, hue_bin_edges, sat_bin_edges\n",
    "\n",
    "def get_dominant_color_in_bounding_box(bounding_box, image: np.ndarray):\n",
    "    hue_hist, sat_hist, hue_bin_edges, sat_bin_edges = get_color_hist_in_bounding_box(bounding_box, image)\n",
    "\n",
    "    if len(hue_hist) == 0 or len(sat_hist) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    dominant_hue_idx = np.argmax(hue_hist)\n",
    "    dominant_hue = (hue_bin_edges[dominant_hue_idx] + hue_bin_edges[dominant_hue_idx + 1]) / 2\n",
    "    dominant_sat_idx = np.argmax(sat_hist)\n",
    "    dominant_sat = (sat_bin_edges[dominant_sat_idx] + sat_bin_edges[dominant_sat_idx + 1]) / 2\n",
    "    return dominant_hue, dominant_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_adjacent_boxes_by_dominant_color(\n",
    "    bounding_boxes, image: np.ndarray, hue_tol=5, sat_tol=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge adjacent bounding boxes if their dominant hue is the same (within hue_tol)\n",
    "    AND their dominant saturation is the same (within sat_tol).\n",
    "    Returns new list of merged bounding boxes.\n",
    "    \"\"\"\n",
    "    if not bounding_boxes:\n",
    "        return []\n",
    "\n",
    "    # Compute dominant hue and dominant saturation for each bounding box\n",
    "    dominant_hues = []\n",
    "    dominant_sats = []\n",
    "    for box in bounding_boxes:\n",
    "        dominant_hue, dominant_sat = get_dominant_color_in_bounding_box(box, image)\n",
    "        dominant_hues.append(dominant_hue)\n",
    "        dominant_sats.append(dominant_sat)\n",
    "\n",
    "    merged_boxes = []\n",
    "    current_box = list(bounding_boxes[0])\n",
    "    current_hue = dominant_hues[0]\n",
    "    current_sat = dominant_sats[0]\n",
    "\n",
    "    for i in range(1, len(bounding_boxes)):\n",
    "        next_box = bounding_boxes[i]\n",
    "        next_hue = dominant_hues[i]\n",
    "        next_sat = dominant_sats[i]\n",
    "\n",
    "        # Check if adjacent (touching or 1-pixel apart in x-direction)\n",
    "        curr_x, curr_y, curr_w, curr_h = current_box\n",
    "        next_x, next_y, next_w, next_h = next_box\n",
    "\n",
    "        same_hue = abs(current_hue - next_hue) <= hue_tol\n",
    "        same_sat = abs(current_sat - next_sat) <= sat_tol\n",
    "        same_color = same_hue and same_sat\n",
    "\n",
    "        if same_color:\n",
    "            # Merge boxes\n",
    "            new_x = min(curr_x, next_x)\n",
    "            new_y = min(curr_y, next_y)\n",
    "            new_w = max(curr_x + curr_w, next_x + next_w) - new_x\n",
    "            new_h = max(curr_y + curr_h, next_y + next_h) - new_y\n",
    "            current_box = [new_x, new_y, new_w, new_h]\n",
    "            # keep current_hue/current_sat unchanged for next check\n",
    "        else:\n",
    "            merged_boxes.append(tuple(current_box))\n",
    "            current_box = list(next_box)\n",
    "            current_hue = next_hue\n",
    "            current_sat = next_sat\n",
    "\n",
    "    merged_boxes.append(tuple(current_box))\n",
    "    return merged_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added this part\n",
    "# ================================================================\n",
    "# Color/shape‑aware splitting + merging\n",
    "# ================================================================\n",
    "# This block of code is responsible for:\n",
    "#   • splits *wide* boxes when there is evidence of two side‑by‑side letters,\n",
    "#   • then tries to merge back only when colors truly match and geometry says\n",
    "#     it was the same glyph (to undo spurious over‑splits).\n",
    "#\n",
    "# Overview of the split pipeline inside `split_boxes_by_dominant_color`:\n",
    "#   (0) Color‑scan ΔE cut         → pick the x with strongest color jump (Lab)\n",
    "#   (1) Watershed (multi‑peak)    → if two DT peaks exist, cut along basin\n",
    "#   (2) Watershed (two‑seed)      → force one seed per half; split by watershed\n",
    "#   (3) Min‑cost seam (geometry)  → seam prefers valleys; cut along it\n",
    "#   (4) 1‑D kmeans on x‑coords    → quick binary clustering of ink columns\n",
    "#   (5) Projection valley         → classic histogram valley split\n",
    "#   (M) Merge by color & shape    → ΔE small + side‑by‑side + no real valley\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Logging (overwrite split_log.txt on every run)\n",
    "# ------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    filename='split_log.txt',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(message)s',\n",
    "    force=True\n",
    ")\n",
    "log = logging.getLogger('split').info\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Utilities\n",
    "# ================================================================\n",
    "def _safe_bbox_from_mask(mask: np.ndarray):\n",
    "    \"\"\"Return bounding rect of nonzero mask or None.\"\"\"\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return None\n",
    "    return cv2.boundingRect(np.vstack(cnts))\n",
    "\n",
    "\n",
    "def _deltaE76(lab1, lab2):\n",
    "    \"\"\"CIE76 ΔE between two Lab triples, lab L in 0..100, a/b in -128..127.\"\"\"\n",
    "    dL = lab1[0] - lab2[0]\n",
    "    da = lab1[1] - lab2[1]\n",
    "    db = lab1[2] - lab2[2]\n",
    "    return float(np.sqrt(dL*dL + da*da + db*db))\n",
    "\n",
    "\n",
    "def _median_lab_in_box(image_rgb: np.ndarray, mask_bin: np.ndarray, x: int, y: int, w: int, h: int):\n",
    "    \"\"\"\n",
    "    Median Lab over *foreground only* inside a box. Returns (L,a,b) or None if too few pixels.\n",
    "    \"\"\"\n",
    "    roi_rgb = image_rgb[y:y+h, x:x+w]\n",
    "    roi_msk = mask_bin[y:y+h, x:x+w] > 0\n",
    "    if roi_msk.sum() < 10:\n",
    "        return None\n",
    "    lab = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2LAB).astype(np.float32)\n",
    "    L = lab[..., 0] * (100.0 / 255.0)\n",
    "    a = lab[..., 1] - 128.0\n",
    "    b = lab[..., 2] - 128.0\n",
    "    Ls = L[roi_msk]; as_ = a[roi_msk]; bs = b[roi_msk]\n",
    "    return (float(np.median(Ls)), float(np.median(as_)), float(np.median(bs)))\n",
    "\n",
    "\n",
    "def _box_majority_cluster_id(box: Tuple[int,int,int,int],\n",
    "                             cluster_masks: Optional[List[np.ndarray]]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Assign a cluster id to a bounding box by majority-ink overlap with the given\n",
    "    k-means cluster masks. Returns None if cluster_masks is not provided.\n",
    "    \"\"\"\n",
    "    if cluster_masks is None:\n",
    "        return None\n",
    "    x, y, w, h = box\n",
    "    best_i, best_cnt = None, -1\n",
    "    for i, m in enumerate(cluster_masks):\n",
    "        roi = m[y:y+h, x:x+w]\n",
    "        cnt = int(np.count_nonzero(roi))  # masks are 0/255; nonzero counts pixels\n",
    "        if cnt > best_cnt:\n",
    "            best_cnt = cnt\n",
    "            best_i = i\n",
    "    return best_i\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  ΔE helper for colour-change “soft edges”\n",
    "# ================================================================\n",
    "def _lab_max_neighbor_deltaE(lab_f32: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For each pixel, the max ΔE to any of its 8 neighbors (big values = strong color edge).\n",
    "    Used as an auxiliary 'edge' map for watershed.\n",
    "    \"\"\"\n",
    "    L = lab_f32[..., 0] * (100.0 / 255.0)\n",
    "    a = lab_f32[..., 1] - 128.0\n",
    "    b = lab_f32[..., 2] - 128.0\n",
    "\n",
    "    H, W = L.shape\n",
    "    maxDE = np.zeros((H, W), dtype=np.float32)\n",
    "    shifts = [(-1,-1),(0,-1),(1,-1),\n",
    "              (-1, 0),       (1, 0),\n",
    "              (-1, 1),(0, 1),(1, 1)]\n",
    "    for dx, dy in shifts:\n",
    "        L2 = np.roll(L, (dy, dx), axis=(0, 1))\n",
    "        a2 = np.roll(a, (dy, dx), axis=(0, 1))\n",
    "        b2 = np.roll(b, (dy, dx), axis=(0, 1))\n",
    "        DE = np.sqrt((L - L2)**2 + (a - a2)**2 + (b - b2)**2)\n",
    "\n",
    "        if dy > 0: DE[:dy, :] = 0\n",
    "        elif dy < 0: DE[dy:, :] = 0\n",
    "        if dx > 0: DE[:, :dx] = 0\n",
    "        elif dx < 0: DE[:, dx:] = 0\n",
    "        maxDE = np.maximum(maxDE, DE)\n",
    "    return maxDE\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  (0) Color-scan ΔE splitter (left→right or top→bottom)\n",
    "# ================================================================\n",
    "def _split_by_color_change_scan(\n",
    "    roi_rgb: np.ndarray,\n",
    "    roi_bin: np.ndarray,\n",
    "    x0: int, y0: int,\n",
    "    axis: str = 'auto',         \n",
    "    window_frac: float = 0.08,  \n",
    "    min_deltaE: float = 5.5,    \n",
    "    min_part_ratio: float = 0.10,\n",
    "    min_sub_area: int = 20\n",
    "):\n",
    "    \"\"\"\n",
    "    Slide a vertical (or horizontal) 'decision line' across the ROI.\n",
    "    At each position compare median Lab of LEFT window vs RIGHT window → ΔE.\n",
    "    If max ΔE is strong enough, split there (plus shape sanity checks).\n",
    "    \"\"\"\n",
    "    h, w = roi_bin.shape\n",
    "    if axis == 'auto':\n",
    "        axis = 'vertical' if w >= h else 'horizontal'\n",
    "\n",
    "    if axis == 'horizontal':\n",
    "        boxes = _split_by_color_change_scan(\n",
    "            roi_rgb.transpose(1, 0, 2), roi_bin.T, y0, x0,\n",
    "            axis='vertical', window_frac=window_frac, min_deltaE=min_deltaE,\n",
    "            min_part_ratio=min_part_ratio, min_sub_area=min_sub_area\n",
    "        )\n",
    "        if boxes is None:\n",
    "            return None\n",
    "        return [(b[1], b[0], b[3], b[2]) for b in boxes]\n",
    "\n",
    "    if w < 8 or h < 6:\n",
    "        return None\n",
    "\n",
    "    fg = (roi_bin > 0)\n",
    "    if not np.any(fg):\n",
    "        return None\n",
    "\n",
    "    lab = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2LAB).astype(np.float32)\n",
    "    L = lab[..., 0] * (100.0 / 255.0)\n",
    "    a = lab[..., 1] - 128.0\n",
    "    b = lab[..., 2] - 128.0\n",
    "\n",
    "    col_L = np.full(w, np.nan, dtype=np.float32)\n",
    "    col_a = np.full(w, np.nan, dtype=np.float32)\n",
    "    col_b = np.full(w, np.nan, dtype=np.float32)\n",
    "    for j in range(w):\n",
    "        rows = np.where(fg[:, j])[0]\n",
    "        if rows.size >= 2:\n",
    "            col_L[j] = np.median(L[rows, j])\n",
    "            col_a[j] = np.median(a[rows, j])\n",
    "            col_b[j] = np.median(b[rows, j])\n",
    "\n",
    "    def _interp_nan(x):\n",
    "        idx = np.where(~np.isnan(x))[0]\n",
    "        if idx.size == 0:\n",
    "            return None\n",
    "        if idx.size < w:\n",
    "            x = x.copy()\n",
    "            x[np.isnan(x)] = np.interp(np.where(np.isnan(x))[0], idx, x[idx])\n",
    "        return x\n",
    "\n",
    "    col_L = _interp_nan(col_L); col_a = _interp_nan(col_a); col_b = _interp_nan(col_b)\n",
    "    if col_L is None:\n",
    "        return None\n",
    "\n",
    "    k = max(3, int(round(w * 0.05)))\n",
    "    if k % 2 == 0: k += 1\n",
    "    col_L = cv2.blur(col_L.reshape(1, -1), (1, k)).flatten()\n",
    "    col_a = cv2.blur(col_a.reshape(1, -1), (1, k)).flatten()\n",
    "    col_b = cv2.blur(col_b.reshape(1, -1), (1, k)).flatten()\n",
    "\n",
    "    m = max(2, int(round(w * window_frac)))\n",
    "    if 2 * m + 2 >= w:\n",
    "        m = max(2, (w // 4))\n",
    "\n",
    "    def _runsum(arr):\n",
    "        c = np.cumsum(arr, dtype=np.float64)\n",
    "        return np.r_[0.0, c]\n",
    "\n",
    "    Lc, ac, bc = _runsum(col_L), _runsum(col_a), _runsum(col_b)\n",
    "\n",
    "    def _mean(cum, s, e):\n",
    "        n = max(1, e - s)\n",
    "        return (cum[e] - cum[s]) / n\n",
    "\n",
    "    best_j, best_de = None, -1.0\n",
    "    j_lo, j_hi = m, w - m\n",
    "    for j in range(j_lo, j_hi):\n",
    "        LL = _mean(Lc, j - m, j);  LR = _mean(Lc, j, j + m)\n",
    "        aL = _mean(ac, j - m, j);  aR = _mean(ac, j, j + m)\n",
    "        bL = _mean(bc, j - m, j);  bR = _mean(bc, j, j + m)\n",
    "        de = np.sqrt((LL - LR)**2 + (aL - aR)**2 + (bL - bR)**2)\n",
    "        if de > best_de:\n",
    "            best_de, best_j = de, j\n",
    "\n",
    "    if best_j is None or best_de < min_deltaE:\n",
    "        return None \n",
    "\n",
    "    left_mask  = roi_bin[:, :best_j]\n",
    "    right_mask = roi_bin[:, best_j:]\n",
    "    if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "        return None\n",
    "\n",
    "    total = float(roi_bin.sum())\n",
    "    left_area  = float(left_mask.sum())\n",
    "    right_area = float(right_mask.sum())\n",
    "    if (left_area < min_part_ratio * total) or (right_area < min_part_ratio * total):\n",
    "        return None\n",
    "\n",
    "    lb = _safe_bbox_from_mask(left_mask)\n",
    "    rb = _safe_bbox_from_mask(right_mask)\n",
    "    if lb is None or rb is None:\n",
    "        return None\n",
    "    lx, ly, lw, lh = lb\n",
    "    rx, ry, rw, rh = rb\n",
    "    top = max(ly, ry); bot = min(ly + lh, ry + rh)\n",
    "    y_ov = max(0, bot - top) / max(1.0, min(lh, rh))\n",
    "\n",
    "    if y_ov < 0.35:\n",
    "        return None\n",
    "\n",
    "    left_box  = (x0 + lx, y0 + ly, lw, lh)\n",
    "    right_box = (x0 + best_j + rx, y0 + ry, rw, rh)\n",
    "    return [left_box, right_box]\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Minimum-cost seam (geometry-only splitter)\n",
    "# ================================================================\n",
    "def _min_seam_cut(roi_bin: np.ndarray, orientation: str = 'vertical') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Dynamic-programming seam on distance transform:\n",
    "    the seam prefers valleys (cheap), avoids ink cores (expensive).\n",
    "    \"\"\"\n",
    "    assert orientation in ('vertical', 'horizontal')\n",
    "    if orientation == 'horizontal':\n",
    "        return _min_seam_cut(roi_bin.T, 'vertical').T\n",
    "    h, w = roi_bin.shape\n",
    "    if h < 3 or w < 3:\n",
    "        return np.zeros_like(roi_bin, dtype=np.uint8)\n",
    "    roi_filled = cv2.morphologyEx(roi_bin, cv2.MORPH_CLOSE, np.ones((3,3), np.uint8), iterations=1)\n",
    "    dt = cv2.distanceTransform((roi_filled > 0).astype(np.uint8) * 255, cv2.DIST_L2, 3)\n",
    "    if dt.max() <= 1e-6:\n",
    "        return np.zeros_like(roi_bin, dtype=np.uint8)\n",
    "    cost = dt / (dt.max() + 1e-6)\n",
    "    dp = cost.copy(); back = np.zeros_like(roi_bin, dtype=np.int16)\n",
    "    for y in range(1, h):\n",
    "        prev = dp[y-1]\n",
    "        left  = np.r_[np.inf, prev[:-1]]\n",
    "        mid   = prev\n",
    "        right = np.r_[prev[1:], np.inf]\n",
    "        opts  = np.vstack([left, mid, right])\n",
    "        arg   = np.argmin(opts, axis=0)\n",
    "        dp[y] = cost[y] + opts[arg, np.arange(w)]\n",
    "        back[y] = (arg - 1).astype(np.int16)\n",
    "    x = int(np.argmin(dp[-1]))\n",
    "    seam = np.zeros_like(roi_bin, dtype=np.uint8)\n",
    "    for y in range(h-1, -1, -1):\n",
    "        seam[y, x] = 255\n",
    "        x = int(np.clip(x + back[y, x], 0, w-1))\n",
    "    return seam\n",
    "\n",
    "\n",
    "def _split_by_min_seam(roi_bin: np.ndarray, x0: int, y0: int,\n",
    "                       orientation: str = 'vertical',\n",
    "                       seam_thickness: int = 3,\n",
    "                       min_part_ratio: float = 0.12):\n",
    "    \"\"\"\n",
    "    Turn seam into a narrow gap, run CC, keep two biggest acceptable parts.\n",
    "    \"\"\"\n",
    "    ker = np.ones((3,3), np.uint8)\n",
    "    roi_filled = cv2.morphologyEx(roi_bin, cv2.MORPH_CLOSE, ker, iterations=1)\n",
    "    seam = _min_seam_cut(roi_filled, orientation)\n",
    "    if seam.sum() == 0:\n",
    "        return None\n",
    "    gap = cv2.dilate(seam, np.ones((seam_thickness, seam_thickness), np.uint8), iterations=1)\n",
    "    cut = roi_filled.copy(); cut[gap > 0] = 0\n",
    "    num, lab, stats, _ = cv2.connectedComponentsWithStats(cut, 8)\n",
    "    if num < 3:\n",
    "        return None\n",
    "    fg = int((roi_filled > 0).sum())\n",
    "    parts = []\n",
    "    for i in range(1, num):\n",
    "        area = int(stats[i, cv2.CC_STAT_AREA])\n",
    "        if area < max(25, int(min_part_ratio*fg)):\n",
    "            continue\n",
    "        x, y, w, h = (int(stats[i, cv2.CC_STAT_LEFT]),\n",
    "                      int(stats[i, cv2.CC_STAT_TOP]),\n",
    "                      int(stats[i, cv2.CC_STAT_WIDTH]),\n",
    "                      int(stats[i, cv2.CC_STAT_HEIGHT]))\n",
    "        parts.append((x0 + x, y0 + y, w, h))\n",
    "    if len(parts) >= 2:\n",
    "        parts.sort(key=lambda b: b[0] if orientation=='vertical' else b[1])\n",
    "        return parts[:2]\n",
    "    return None\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Simple fallbacks (fast heuristics)\n",
    "# ================================================================\n",
    "def _fallback_projection_split(x, y, w, h, roi_bin: np.ndarray):\n",
    "    \"\"\"\n",
    "    Classic vertical projection valley split (smoothed).\n",
    "    \"\"\"\n",
    "    if w < 6 or h < 3:\n",
    "        return [(x, y, w, h)]\n",
    "    col_sum = roi_bin.sum(axis=0).astype(np.float32)\n",
    "    bw = max(5, int(round(w * 0.05)))\n",
    "    if bw % 2 == 0: bw += 1\n",
    "    col_sum = cv2.blur(col_sum.reshape(1, -1), (1, bw)).flatten()\n",
    "    valley_idx = int(np.argmin(col_sum[2:-2])) + 2\n",
    "    if col_sum[valley_idx] < 0.40 * (col_sum.max() + 1e-6):\n",
    "        lw, rw = valley_idx, w - valley_idx\n",
    "        if lw >= 3 and rw >= 3:\n",
    "            return [(x, y, lw, h), (x + valley_idx, y, rw, h)]\n",
    "    return [(x, y, w, h)]\n",
    "\n",
    "\n",
    "def _split_by_x_kmeans_binary(roi_bin: np.ndarray, x0: int, y0: int, min_part_ratio=0.10):\n",
    "    \"\"\"\n",
    "    Quick 1‑D k-means on foreground X positions → two clusters → cut in between.\n",
    "    \"\"\"\n",
    "    ys, xs = np.where(roi_bin > 0)\n",
    "    if xs.size < 20: return None\n",
    "    c1, c2 = float(xs.min()), float(xs.max())\n",
    "    for _ in range(15):\n",
    "        d1 = np.abs(xs - c1); d2 = np.abs(xs - c2)\n",
    "        mask = d1 <= d2\n",
    "        if mask.sum() == 0 or (~mask).sum() == 0: break\n",
    "        c1 = xs[mask].mean(); c2 = xs[~mask].mean()\n",
    "    cut = int(round((c1 + c2) / 2))\n",
    "    if cut <= 1 or cut >= roi_bin.shape[1] - 1: return None\n",
    "    left, right = roi_bin[:, :cut], roi_bin[:, cut:]\n",
    "    if left.sum() == 0 or right.sum() == 0: return None\n",
    "    total = float(roi_bin.sum())\n",
    "    if min(left.sum(), right.sum()) < min_part_ratio * total: return None\n",
    "    boxes = []\n",
    "    for sub, xoff in [(left, 0), (right, cut)]:\n",
    "        bb = _safe_bbox_from_mask(sub)\n",
    "        if bb is None: return None\n",
    "        x, y, w, h = bb\n",
    "        boxes.append((x0 + x + xoff, y0 + y, w, h))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Two-seed watershed (shape-first splitter)\n",
    "# ================================================================\n",
    "def _two_seed_watershed(roi_bin: np.ndarray, roi_rgb: np.ndarray, edges: np.ndarray | None):\n",
    "    \"\"\"\n",
    "    Watershed with one seed per half (left/right). Encourages two-letter splits.\n",
    "    \"\"\"\n",
    "    h, w = roi_bin.shape\n",
    "    if w < 6 or h < 6:\n",
    "        return None\n",
    "\n",
    "    dist = cv2.distanceTransform(roi_bin, cv2.DIST_L2, 3)\n",
    "    if dist.max() < 1.2:\n",
    "        return None\n",
    "\n",
    "    mid = w // 2\n",
    "    ldt, rdt = dist[:, :mid], dist[:, mid:]\n",
    "    if ldt.size == 0 or rdt.size == 0:\n",
    "        return None\n",
    "\n",
    "    y1, x1 = np.unravel_index(np.argmax(ldt), ldt.shape)\n",
    "    y2, x2 = np.unravel_index(np.argmax(rdt), rdt.shape); x2 += mid\n",
    "\n",
    "    markers = np.zeros((h, w), np.int32)\n",
    "    cv2.circle(markers, (int(x1), int(y1)), 3, 1, -1)\n",
    "    cv2.circle(markers, (int(x2), int(y2)), 4, 2, -1)\n",
    "\n",
    "    unknown = (roi_bin == 0).astype(np.uint8) * 255\n",
    "    if edges is not None:\n",
    "        unknown = cv2.bitwise_or(unknown, edges)\n",
    "\n",
    "    ws_markers = markers.copy()\n",
    "    ws_markers[unknown == 255] = 0\n",
    "    ws_markers = ws_markers + 1\n",
    "\n",
    "    roi_bgr = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.watershed(roi_bgr, ws_markers)\n",
    "\n",
    "    masks = []\n",
    "    ker = np.ones((3,3), np.uint8)\n",
    "    for label in (2, 3):\n",
    "        m = (ws_markers == label).astype(np.uint8) * 255\n",
    "        if m.sum() == 0:\n",
    "            return None\n",
    "        m = cv2.morphologyEx(m, cv2.MORPH_OPEN, ker, iterations=1)\n",
    "        masks.append(m)\n",
    "    return masks\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  (M) Merge by color & shallow‑valley (post‑split repair)\n",
    "# ================================================================\n",
    "def _pair_band_metrics(b1, b2, mask_bin: np.ndarray):\n",
    "    \"\"\"\n",
    "    Measure geometry between adjacent boxes:\n",
    "      - vertical overlap,\n",
    "      - raw gap and width of the 'band' between them,\n",
    "      - how empty that band is (rows fully bg, valley strength),\n",
    "      - whether a tiny close fuses everything into 1 CC (a hint of same glyph).\n",
    "    \"\"\"\n",
    "    (x1, y1, w1, h1) = b1\n",
    "    (x2, y2, w2, h2) = b2\n",
    "    xL = min(x1, x2); yT = min(y1, y2)\n",
    "    xR = max(x1 + w1, x2 + w2); yB = max(y1 + h1, y2 + h2)\n",
    "    W = xR - xL; H = yB - yT\n",
    "    roi = (mask_bin[yT:yB, xL:xR] > 0).astype(np.uint8) * 255\n",
    "\n",
    "    top = max(y1, y2); bot = min(y1 + h1, y2 + h2)\n",
    "    y_ov = max(0, bot - top) / max(1.0, min(h1, h2))\n",
    "\n",
    "    gap = x2 - (x1 + w1) \n",
    "    left_end_local    = max(0, (x1 + w1) - xL)\n",
    "    right_start_local = max(0, x2 - xL)\n",
    "    band_w = max(0, right_start_local - left_end_local)\n",
    "\n",
    "    rows_bg_only_ratio = 0.0\n",
    "    valley_mean_ratio  = 1.0\n",
    "    if band_w > 0:\n",
    "        band = roi[:, left_end_local:right_start_local]\n",
    "        rows_bg_only_ratio = float(np.mean(np.sum(band, axis=1) == 0))\n",
    "        col_sum = band.sum(axis=0).astype(np.float32)\n",
    "        ref = max(1.0, roi.sum(axis=0).max())\n",
    "        valley_mean_ratio = float(col_sum.mean() / ref)  \n",
    "\n",
    "    ker = np.ones((3,3), np.uint8)\n",
    "    roi_close = cv2.morphologyEx(roi, cv2.MORPH_CLOSE, ker, iterations=1)\n",
    "    num, labs, stats, _ = cv2.connectedComponentsWithStats(roi_close, 8)\n",
    "    if num <= 1:\n",
    "        cc_single = True\n",
    "    else:\n",
    "        areas = stats[1:, cv2.CC_STAT_AREA].astype(np.float32)\n",
    "        cc_single = (areas.max() / max(1.0, areas.sum())) >= 0.90\n",
    "\n",
    "    return y_ov, int(gap), int(band_w), float(rows_bg_only_ratio), float(valley_mean_ratio), bool(cc_single)\n",
    "\n",
    "\n",
    "def merge_boxes_by_color_and_shape(\n",
    "    boxes,\n",
    "    image_rgb: np.ndarray,\n",
    "    reconstructed_mask: np.ndarray,\n",
    "    median_char_w: float,\n",
    "    de_thresh: float = 7,\n",
    "    min_y_overlap: float = 0.50,\n",
    "    max_gap_px: int = 4,\n",
    "    max_gap_rel_h: float = 0.18,\n",
    "    max_merged_width_ratio: float = 1.60,\n",
    "    *,\n",
    "    image_id: Optional[str] = None,\n",
    "    cluster_masks: Optional[List[np.ndarray]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Merge neighboring boxes *only if*:\n",
    "      - color is sufficiently similar (ΔE <= de_thresh),\n",
    "      - boxes look side-by-side (enough vertical overlap),\n",
    "      - gap small and no strong empty band (or fuses to 1 CC),\n",
    "      - merged width not absurd vs typical width.\n",
    "\n",
    "    Added:\n",
    "      - image_id/cluster_masks: for logging which image/cluster changed.\n",
    "    \"\"\"\n",
    "    if not boxes:\n",
    "        return []\n",
    "\n",
    "    boxes = sorted(list(boxes), key=lambda b: b[0])\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        out = []\n",
    "        i = 0\n",
    "        while i < len(boxes):\n",
    "            if i == len(boxes) - 1:\n",
    "                out.append(boxes[i]); break\n",
    "\n",
    "            b1 = boxes[i]\n",
    "            b2 = boxes[i+1]\n",
    "\n",
    "            y_ov, gap, band_w, rows_bg, valley, cc_single = _pair_band_metrics(b1, b2, reconstructed_mask)\n",
    "\n",
    "            if y_ov >= min_y_overlap:\n",
    "                (x1, y1, w1, h1) = b1\n",
    "                (x2, y2, w2, h2) = b2\n",
    "                near_ok = (gap <= max(max_gap_px, int(round(min(h1, h2) * max_gap_rel_h))))\n",
    "            else:\n",
    "                near_ok = False\n",
    "\n",
    "            if near_ok:\n",
    "                lab1 = _median_lab_in_box(image_rgb, reconstructed_mask, *b1)\n",
    "                lab2 = _median_lab_in_box(image_rgb, reconstructed_mask, *b2)\n",
    "                if (lab1 is not None) and (lab2 is not None):\n",
    "                    de = _deltaE76(lab1, lab2)\n",
    "                else:\n",
    "                    de = 999.0\n",
    "\n",
    "                shallow_band = (band_w == 0) or (rows_bg <= 0.70) or (valley >= 0.20) or cc_single\n",
    "\n",
    "                xL = min(x1, x2); xR = max(x1 + w1, x2 + w2)\n",
    "                merged_w = xR - xL\n",
    "                not_too_wide = (median_char_w == 0) or (merged_w <= max_merged_width_ratio * median_char_w)\n",
    "\n",
    "                if (de <= de_thresh) and shallow_band and not_too_wide:\n",
    "                    yT = min(y1, y2); yB = max(y1 + h1, y2 + h2)\n",
    "                    merged_box = (xL, yT, merged_w, yB - yT)\n",
    "\n",
    "                    # --- logging with image & cluster id of the merged result\n",
    "                    cid_m = _box_majority_cluster_id(merged_box, cluster_masks)\n",
    "                    img_txt = image_id if image_id is not None else \"?\"\n",
    "                    cid_txt = cid_m if cid_m is not None else \"?\"\n",
    "\n",
    "                    log(f\"[img={img_txt}][cid={cid_txt}] \"\n",
    "                        f\"[{x1},{y1},{w1},{h1}] + [{x2},{y2},{w2},{h2}] \"\n",
    "                        f\"-> (M) merge-by-color | ΔE={de:.1f} gap={gap} yOV={y_ov:.2f} \"\n",
    "                        f\"bandW={band_w} rowsBG={rows_bg:.2f} valley={valley:.2f} \"\n",
    "                        f\"ccSingle={int(cc_single)} | merged_w={merged_w} (median≈{median_char_w:.1f})\")\n",
    "\n",
    "                    out.append(merged_box)\n",
    "                    i += 2\n",
    "                    merged = True\n",
    "                    continue\n",
    "\n",
    "            out.append(b1)\n",
    "            i += 1\n",
    "\n",
    "        boxes = out\n",
    "\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  Master orchestrator\n",
    "# ================================================================\n",
    "def split_boxes_by_dominant_color(\n",
    "    bounding_boxes,\n",
    "    image_clean: np.ndarray,\n",
    "    reconstructed_mask: np.ndarray,\n",
    "    widen_ratio: float = 1.06,\n",
    "    deltaE_edge: float = 6.0,\n",
    "    min_sub_area: int = 20,\n",
    "    *,\n",
    "    image_id: Optional[str] = None,\n",
    "    cluster_masks: Optional[List[np.ndarray]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Given initial boxes, try multiple splitters in sequence for 'suspiciously wide' boxes,\n",
    "    then run a conservative merge (M) to fix over-splitting when color matches.\n",
    "\n",
    "    Added:\n",
    "      - image_id: filename/basename for logging\n",
    "      - cluster_masks: cluster masks to determine which cluster a split/merge affected\n",
    "      - logs like: [img=<file>][cid=<kmeans cluster idx>] -> (method) accepted\n",
    "    \"\"\"\n",
    "    if not bounding_boxes:\n",
    "        return []\n",
    "\n",
    "    boxes  = sorted(bounding_boxes, key=lambda b: b[0])\n",
    "    widths = [w for (_,_,w,_) in boxes]\n",
    "    median_w = np.median(widths) if widths else 0.0\n",
    "\n",
    "    out = []\n",
    "    kernel3 = np.ones((3,3), np.uint8)\n",
    "\n",
    "    for (x, y, w, h) in boxes:\n",
    "        aspect_wide = (w / (h + 1e-6)) >= 0.78\n",
    "        suspicious = (median_w == 0) or (w >= widen_ratio * median_w) or (aspect_wide and w >= median_w)\n",
    "        if not suspicious:\n",
    "            out.append((x, y, w, h))\n",
    "            continue\n",
    "\n",
    "        # determine cluster id of the *parent* box for logging\n",
    "        parent_box = (x, y, w, h)\n",
    "        parent_cid = _box_majority_cluster_id(parent_box, cluster_masks)\n",
    "        img_txt = image_id if image_id is not None else \"?\"\n",
    "        cid_txt = parent_cid if parent_cid is not None else \"?\"\n",
    "\n",
    "        roi_rgb  = image_clean[y:y+h, x:x+w]\n",
    "        roi_mask = reconstructed_mask[y:y+h, x:x+w]\n",
    "        roi_bin  = (roi_mask > 0).astype(np.uint8) * 255\n",
    "        if roi_bin.sum() == 0:\n",
    "            out.append((x, y, w, h))\n",
    "            continue\n",
    "\n",
    "        roi_filled = cv2.morphologyEx(roi_bin, cv2.MORPH_CLOSE, kernel3, iterations=1)\n",
    "        lab   = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2LAB).astype(np.float32)\n",
    "        maxDE = _lab_max_neighbor_deltaE(lab)\n",
    "        edges = (maxDE >= deltaE_edge).astype(np.uint8) * 255\n",
    "        edges = cv2.dilate(edges, kernel3, iterations=1)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # (0) Color-scan ΔE cut (vertical first; optional horizontal)\n",
    "        # ------------------------------------------------------------\n",
    "        split_done = False\n",
    "        for axis in (('vertical' if w >= h else 'vertical'),  # try vertical first always\n",
    "                     ('horizontal' if h > 1.25*w else None)):\n",
    "            if axis is None:\n",
    "                continue\n",
    "            cc = _split_by_color_change_scan(\n",
    "                roi_rgb, roi_bin, x, y,\n",
    "                axis=axis, window_frac=0.08, min_deltaE=5.5,\n",
    "                min_part_ratio=0.10, min_sub_area=min_sub_area\n",
    "            )\n",
    "            if cc is not None:\n",
    "                # NOTE: (0) always returns exactly 2 parts\n",
    "                log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (0) color-scan {axis} | accepted | parts=2\")\n",
    "                out.extend(sorted(cc, key=lambda b: b[0]))\n",
    "                split_done = True\n",
    "                break\n",
    "        if split_done:\n",
    "            continue\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # (1) Multi-peak watershed (can produce >= 2 parts)\n",
    "        # ------------------------------------------------------------\n",
    "        dist = cv2.distanceTransform(roi_filled, cv2.DIST_L2, 3)\n",
    "        thr  = 0.28 * float(dist.max())\n",
    "        peak_mask = (dist >= thr).astype(np.uint8) * 255\n",
    "        peak_mask = cv2.morphologyEx(peak_mask, cv2.MORPH_OPEN, kernel3, iterations=1)\n",
    "        num_peaks, markers = cv2.connectedComponents(peak_mask)\n",
    "\n",
    "        if num_peaks >= 3:  # background + >=2 cores\n",
    "            sure_fg = (peak_mask > 0).astype(np.uint8) * 255\n",
    "            sure_bg = cv2.dilate(roi_filled, kernel3, iterations=2)\n",
    "            unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "            unknown = cv2.bitwise_or(unknown, edges)\n",
    "\n",
    "            ws_markers = markers.copy()\n",
    "            ws_markers[unknown == 255] = 0\n",
    "            ws_markers = ws_markers + 1\n",
    "            roi_bgr = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2BGR)\n",
    "            cv2.watershed(roi_bgr, ws_markers)\n",
    "\n",
    "            sub_boxes = []\n",
    "            for label in range(2, ws_markers.max() + 1):\n",
    "                m = (ws_markers == label).astype(np.uint8) * 255\n",
    "                if m.sum() == 0: continue\n",
    "                m = cv2.morphologyEx(m, cv2.MORPH_OPEN, kernel3, iterations=1)\n",
    "                bb = _safe_bbox_from_mask(m)\n",
    "                if bb is None: continue\n",
    "                x2, y2, w2, h2 = bb\n",
    "                if w2 * h2 >= min_sub_area:\n",
    "                    sub_boxes.append((x + x2, y + y2, w2, h2))\n",
    "\n",
    "            if len(sub_boxes) >= 2:\n",
    "                log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (1) multi-peak watershed | accepted | parts={len(sub_boxes)}\")\n",
    "                out.extend(sorted(sub_boxes, key=lambda b: b[0]))\n",
    "                continue\n",
    "            else:\n",
    "                log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (1) multi-peak watershed | no usable sub-boxes\")\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # (2) Two-seed watershed (returns exactly 2 parts when accepted)\n",
    "        # ------------------------------------------------------------\n",
    "        masks = _two_seed_watershed(roi_filled, roi_rgb, edges)\n",
    "        if masks is not None:\n",
    "            sub_boxes = []\n",
    "            for m in masks:\n",
    "                bb = _safe_bbox_from_mask(m)\n",
    "                if bb is None: continue\n",
    "                x2, y2, w2, h2 = bb\n",
    "                if w2 * h2 >= min_sub_area:\n",
    "                    sub_boxes.append((x + x2, y + y2, w2, h2))\n",
    "            if len(sub_boxes) >= 2:\n",
    "                # two-seed yields 2 masks; we keep 2\n",
    "                log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (2) two-seed watershed | accepted | parts=2\")\n",
    "                out.extend(sorted(sub_boxes, key=lambda b: b[0])[:2])\n",
    "                continue\n",
    "            else:\n",
    "                log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (2) two-seed watershed | no usable sub-boxes\")\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # (3) Minimum-cost seam (returns at most 2 parts)\n",
    "        # ------------------------------------------------------------\n",
    "        orient = 'vertical' if w >= h else 'horizontal'\n",
    "        seam_boxes = _split_by_min_seam(roi_bin, x, y, orientation=orient,\n",
    "                                        seam_thickness=3, min_part_ratio=0.12)\n",
    "        if seam_boxes is not None:\n",
    "            log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (3) min-cost seam | accepted | parts={len(seam_boxes)}\")\n",
    "            out.extend(sorted(seam_boxes, key=lambda b: b[0]))\n",
    "            continue\n",
    "        else:\n",
    "            log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (3) min-cost seam | no split\")\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # (4) 1-D x-kmeans (returns exactly 2 when accepted)\n",
    "        # ------------------------------------------------------------\n",
    "        kboxes = _split_by_x_kmeans_binary(roi_filled, x, y, min_part_ratio=0.10)\n",
    "        if kboxes is not None:\n",
    "            log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (4) x-kmeans 1D | accepted | parts=2\")\n",
    "            out.extend(sorted(kboxes, key=lambda b: b[0]))\n",
    "            continue\n",
    "        else:\n",
    "            log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (4) x-kmeans 1D | no split\")\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # (5) Projection valley (returns 1 or 2)\n",
    "        # ------------------------------------------------------------\n",
    "        pv = _fallback_projection_split(x, y, w, h, roi_bin)\n",
    "        if len(pv) == 2:\n",
    "            log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (5) projection valley | accepted | parts=2\")\n",
    "            out.extend(sorted(pv, key=lambda b: b[0]))\n",
    "            continue\n",
    "        else:\n",
    "            log(f\"[img={img_txt}][cid={cid_txt}] [{x},{y},{w},{h}] -> (5) projection valley | no clear valley\")\n",
    "\n",
    "        # Keep original box if everything declines\n",
    "        out.append((x, y, w, h))\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # (M) Post-pass: merge back over-splits inside single glyphs\n",
    "    # ------------------------------------------------------------\n",
    "    merged_out = merge_boxes_by_color_and_shape(\n",
    "        out, image_clean, reconstructed_mask,\n",
    "        median_char_w=median_w,\n",
    "        de_thresh=7,\n",
    "        min_y_overlap=0.50,\n",
    "        max_gap_px=4,\n",
    "        max_gap_rel_h=0.18,\n",
    "        max_merged_width_ratio=1.60,\n",
    "        image_id=image_id,           \n",
    "        cluster_masks=cluster_masks  \n",
    "    )\n",
    "\n",
    "    if len(merged_out) != len(out):\n",
    "        img_txt = image_id if image_id is not None else \"?\"\n",
    "        log(f\"[img={img_txt}] (M) merged {len(out)} -> {len(merged_out)} boxes\")\n",
    "\n",
    "    log('-> cut off')\n",
    "    return sorted(merged_out, key=lambda b: b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added this part\n",
    "# ================================================================\n",
    "# Visual helpers to see segmented characters\n",
    "# ================================================================\n",
    "def show_char_segments(base_image: np.ndarray,\n",
    "                       reconstructed: np.ndarray,\n",
    "                       bounding_boxes: List[Tuple[int,int,int,int]]) -> None:\n",
    "    boxes = sorted(bounding_boxes, key=lambda b: b[0])\n",
    "    n = len(boxes)\n",
    "    if n == 0:\n",
    "        return\n",
    "    plt.figure(figsize=(1.5 * n, 2))\n",
    "    for i, (x, y, w, h) in enumerate(boxes, 1):\n",
    "        roi_img  = base_image[y:y+h, x:x+w]\n",
    "        roi_mask = (reconstructed[y:y+h, x:x+w] > 0)\n",
    "\n",
    "        char_rgb = np.full((h, w, 3), 255, dtype=np.uint8)\n",
    "        char_rgb[roi_mask] = roi_img[roi_mask]\n",
    "\n",
    "        plt.subplot(1, n, i)\n",
    "        plt.imshow(char_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.title(str(i))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_and_reconstruct(image: np.ndarray, clusters: List[np.ndarray], bounding_boxes: List[Tuple[int, int, int, int]]) -> List[Tuple[int, int, int, int]]:\n",
    "    low_pixel_density_threshold = 0.4\n",
    "    dilation_iterations = 2\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    needs_dilation = False\n",
    "\n",
    "    for x, y, w, h in bounding_boxes:\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        pixel_count = np.count_nonzero(roi)\n",
    "        box_area = w * h\n",
    "        pixel_density = pixel_count / box_area if box_area > 0 else 0\n",
    "        \n",
    "        if pixel_density < low_pixel_density_threshold:\n",
    "            needs_dilation = True\n",
    "            break\n",
    "\n",
    "    dilated_cluster_masks = []\n",
    "    if needs_dilation:\n",
    "        for mask in clusters:\n",
    "            dilated_mask = cv2.dilate(mask, kernel, iterations=dilation_iterations)\n",
    "            dilated_cluster_masks.append(dilated_mask)\n",
    "        \n",
    "        contours = get_contours_from_masks(dilated_cluster_masks)\n",
    "        bounding_boxes = get_bounding_boxes(contours)\n",
    "        reconstructed = reconstruct_from_clusters(dilated_cluster_masks)\n",
    "\n",
    "    return bounding_boxes, dilated_cluster_masks if needs_dilation else clusters, reconstructed if needs_dilation else image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bounding_boxes(bounding_boxes, image):\n",
    "    for x, y, w, h in bounding_boxes:\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_components_masks(image: np.ndarray) -> List[np.ndarray]:\n",
    "    # Ensure image is single channel and binary\n",
    "    if len(image.shape) == 3:\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image_gray = image.copy()\n",
    "    image_gray = cv2.bitwise_not(image_gray)\n",
    "    # Threshold to binary if not already\n",
    "    _, bw = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    num_labels, comp_labels, stats, centroids = cv2.connectedComponentsWithStats(bw, connectivity=8)\n",
    "    masks = []\n",
    "    for i in range(1, num_labels):\n",
    "        mask = np.zeros_like(bw)\n",
    "        mask[comp_labels == i] = 255\n",
    "        masks.append(mask)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(filepath: str, show_images=False):\n",
    "    # 1. Load image\n",
    "    image_id = os.path.basename(filepath)\n",
    "    num_characters = get_characters_from_filename(filepath)[1]\n",
    "    image = load_image(filepath)\n",
    "    image_rgb = get_rgb_image(image)\n",
    "    if show_images:\n",
    "        show_image(image_rgb)\n",
    "\n",
    "    # 2. Clean image (black lines and noise)\n",
    "    image_clean = clean_image(image_rgb)\n",
    "    if show_images:\n",
    "        show_image(image_clean)\n",
    "\n",
    "    # 3. Dilate image\n",
    "    image_dilated = dilate_image(image_clean)\n",
    "    if show_images:\n",
    "        show_image(image_dilated)\n",
    "\n",
    "    # 4. Get k-means clusters\n",
    "    clusters = get_k_means_clusters(image_dilated, num_characters)\n",
    "\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        plt.title(f'Cluster {i}')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cluster, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    # 4. Get connected components masks\n",
    "    # connected_components_masks = get_connected_components_masks(image_dilated)\n",
    "\n",
    "    # # Show clusters masks\n",
    "    # image_dilated_gray = cv2.cvtColor(image_dilated, cv2.COLOR_BGR2GRAY)\n",
    "    # image_dilated_gray = cv2.bitwise_not(image_dilated_gray)\n",
    "    # _, image_dilated_gray = cv2.threshold(image_dilated_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # plt.title('Connected Components Mask')\n",
    "    # plt.imshow(image_dilated_gray, cmap='gray')\n",
    "    # plt.show()\n",
    "\n",
    "    # if show_images:\n",
    "    #     for i, cluster in enumerate(connected_components_masks):\n",
    "    #         plt.title(f'Connected Components Mask {i}')\n",
    "    #         plt.axis('off')\n",
    "    #         plt.imshow(cluster, cmap='gray')\n",
    "    #         plt.show()\n",
    "\n",
    "    # 5. Get contours from clusters\n",
    "    contours = get_contours_from_masks(clusters)\n",
    "\n",
    "    # 6. Reconstruct image from clusters    \n",
    "    reconstructed = reconstruct_from_clusters(clusters)\n",
    "    # show_image(reconstructed)\n",
    "\n",
    "    # 6. Get bounding boxes from countours of cluster masks\n",
    "    bounding_boxes = get_bounding_boxes(contours)\n",
    "\n",
    "    # =============================\n",
    "    # Bounding boxes post-processing\n",
    "    # =============================\n",
    "    iteration = 0\n",
    "    while len(bounding_boxes) != num_characters and iteration < num_characters:\n",
    "        # 7. Merge small boxes with nearby larger boxes\n",
    "        if len(bounding_boxes) > num_characters: # Too many bounding boxes\n",
    "            log(f\"[{image_id}] boxes={len(bounding_boxes)} , chars={num_characters} (iteration={iteration})\")\n",
    "            \n",
    "            bounding_boxes, _, reconstructed = dilate_and_reconstruct(reconstructed, clusters, bounding_boxes)\n",
    "\n",
    "            bounding_boxes = merge_boxes_small_nearby(bounding_boxes, width_threshold=0.5, height_threshold=0.5, distance_threshold=30)\n",
    "\n",
    "            bounding_boxes = merge_boxes_overlapping_x(bounding_boxes, overlap_threshold=0.7)\n",
    "\n",
    "            log(f\"[{image_id}] after (M): boxes={len(bounding_boxes)} , chars={num_characters} (iteration={iteration})\")\n",
    "\n",
    "        elif len(bounding_boxes) < num_characters:\n",
    "            # bounding_boxes = merge_adjacent_boxes_by_dominant_color(bounding_boxes, image)\n",
    "            # Added this part: breaks fused characters—even if same thickness—when colors differ or shapes hint two letters.\n",
    "            log(f\"[{image_id}] enter split: boxes={len(bounding_boxes)} < chars={num_characters} (iteration={iteration})\")\n",
    "            bounding_boxes = split_boxes_by_dominant_color(\n",
    "                bounding_boxes,\n",
    "                image_clean,      \n",
    "                reconstructed,  \n",
    "                widen_ratio=1.10,\n",
    "                deltaE_edge=8.0,\n",
    "                min_sub_area=35,\n",
    "                image_id=image_id,             \n",
    "                cluster_masks=clusters         \n",
    "            )\n",
    "\n",
    "        # Added this part: always keep boxes sorted left-to-right \n",
    "        bounding_boxes = sorted(bounding_boxes, key=lambda b: b[0])\n",
    "        iteration += 1\n",
    "\n",
    "    # 9. Visualize results\n",
    "    reconstructed_color = cv2.cvtColor(reconstructed, cv2.COLOR_GRAY2RGB)\n",
    "    for x, y, w, h in bounding_boxes:\n",
    "        cv2.rectangle(reconstructed_color, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    if show_images:\n",
    "        # Added this part: display each character\n",
    "        show_char_segments(image_rgb, reconstructed, bounding_boxes)\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(reconstructed_color)\n",
    "        plt.title(f'Reconstructed with {len(bounding_boxes)} Bounding Boxes')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    # print(f\"Bounding boxes: {len(bounding_boxes)}\")\n",
    "    # print(f\"Number of characters: {num_characters}\")\n",
    "    if len(bounding_boxes) == num_characters:\n",
    "        return \"correct\"\n",
    "    elif len(bounding_boxes) < num_characters:\n",
    "        return \"smaller\"\n",
    "    else:\n",
    "        return \"larger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(mode: int):\n",
    "    folder_path = 'captchaImages'\n",
    "    filenames = os.listdir(folder_path)\n",
    "\n",
    "    mismatch_count = 0\n",
    "    smaller_count = 0\n",
    "    larger_count = 0\n",
    "\n",
    "    if mode == 1:\n",
    "        mismatch_filenames = []\n",
    "        for filename in tqdm(filenames, desc=\"Processing images\"):\n",
    "            try:\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                match = process_image(image_path)\n",
    "                if match != 'correct':\n",
    "                    mismatch_count += 1\n",
    "                    if match == 'smaller':\n",
    "                        smaller_count += 1\n",
    "                    else:\n",
    "                        larger_count += 1\n",
    "                    mismatch_filenames.append(filename)\n",
    "            except Exception as e:\n",
    "                mismatch_filenames.append(f\"Error: {filename}\")\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "        print(f\"Mismatch count: {mismatch_count}\")\n",
    "        print(f\"Smaller count: {smaller_count}\")\n",
    "        print(f\"Larger count: {larger_count}\")\n",
    "\n",
    "        # Save mismatch filenames to a text file\n",
    "        with open(\"mismatches_4.txt\", \"w\") as f:\n",
    "            for name in mismatch_filenames:\n",
    "                f.write(name + \"\\n\")\n",
    "\n",
    "    elif mode == 2:\n",
    "        # Read image filenames from mismatches.txt and process them\n",
    "        # with open(\"mismatches_4.txt\", \"r\") as f:\n",
    "        #     image_paths = [line.strip() for line in f if line.strip()]\n",
    "        #     total_files = len(image_paths)\n",
    "        # for image_path in image_paths[:5]:\n",
    "        #     match = process_image(os.path.–join('data/train', image_path), show_images=True)\n",
    "        #     if match != 'correct':\n",
    "        #         mismatch_count += 1\n",
    "        #         if match == 'smaller':\n",
    "        #             smaller_count += 1\n",
    "        #         else:\n",
    "        #             larger_count += 1\n",
    "\n",
    "        for filename in filenames:\n",
    "            match = process_image(os.path.join('captchaImages', filename), show_images=True)\n",
    "        \n",
    "        print(f\"Mismatch count: {mismatch_count}\")\n",
    "        print(f\"Smaller count: {smaller_count}\")\n",
    "        print(f\"Larger count: {larger_count}\")\n",
    "\n",
    "run(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
